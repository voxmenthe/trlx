{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import trlx\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from typing import List\n",
    "from trlx.data.configs import TRLConfig\n",
    "# from yaml import save_load\n",
    "\n",
    "default_config = yaml.safe_load(open('configs/ppo_config.yml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a reward function. It takes the outputs of the LM and gives a score - this is what the RL algorithm optimizes. In this case, we want positive movie reviews so we use a sentiment classifier trained on human annotations to serve as our reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a301140f248229bab8ff5df0e3990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install ipywidgets\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentiment_fn = pipeline(\"sentiment-analysis\", \"lvwerra/distilbert-imdb\",\n",
    "                        top_k=2, truncation=True, batch_size=256, device=device)\n",
    "\n",
    "def get_positive_score(scores):\n",
    "    \"Extract value associated witha positive sentiment from pipeline's output\"\n",
    "    return dict(map(lambda x: tuple(x.values()), scores))['POSITIVE']\n",
    "\n",
    "\n",
    "def reward_fn(samples: List[str]) -> List[float]:\n",
    "    \"Reward function that takes a list of samples and returns a list of rewards\"\n",
    "    sentiments = list(map(get_positive_score, sentiment_fn(samples)))\n",
    "    return sentiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's load the IMDB dataset and get some text for the language model to complete. For each of the reviews, just the first four words are given, and the LM must learn complete the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/jeffcoggshall/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    }
   ],
   "source": [
    "# Take first few words off of the movie reviews as prompts\n",
    "imdb = load_dataset(\"imdb\", split=\"train+test\")\n",
    "prompts = [\" \".join(review.split()[:4]) for review in imdb[\"text\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a config, reward model and the dataset ready, you are now set to train a language model with RL!\n",
    "\n",
    "Some eval prompts are also passed in and the reward model score of the generations by your trained LM will be reported. \n",
    "\n",
    "Hopefully, at the end of RL training, it's high!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams={}\n",
    "\n",
    "config = TRLConfig.update(default_config, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRLConfig(method=PPOConfig(name='ppoconfig', ppo_epochs=4, num_rollouts=128, chunk_size=128, init_kl_coef=0.05, target=6, horizon=10000, gamma=1, lam=0.95, cliprange=0.2, cliprange_value=0.2, vf_coef=1, scale_reward=False, ref_mean=None, ref_std=None, cliprange_reward=10, gen_kwargs={'max_new_tokens': 40, 'top_k': 0, 'top_p': 1.0, 'do_sample': True}), model=ModelConfig(model_type='AcceleratePPOModel', model_path='lvwerra/gpt2-imdb', tokenizer_path='gpt2', num_layers_unfrozen=2), optimizer=OptimizerConfig(name='adamw', kwargs={'lr': 0.0001, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 1e-06}), scheduler=SchedulerConfig(name='cosine_annealing', kwargs={'T_max': 10000, 'eta_min': 0.0001}), train=TrainConfig(total_steps=10000, seq_length=1024, epochs=100, batch_size=128, checkpoint_interval=10000, eval_interval=100, pipeline='PromptPipeline', orchestrator='PPOOrchestrator', project_name='trlx', entity_name=None, checkpoint_dir='ckpts', rollout_logging_dir=None, seed=42))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24109ec82df42e2b3b0cfbe289c507c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd36ccae5004c259beb2665a69dd0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0598f55f24154e50be384e9ecd21c485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88a587416a24ed894f37031a695e2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d3ac8704d14b9bbaa51fc0edea1d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d17462f4e54de983077e15b43864d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = trlx.train(\n",
    "    reward_fn=reward_fn,\n",
    "    prompts=prompts,\n",
    "    eval_prompts=[\"I don't know much about Hungarian underground\"]  * 64,\n",
    "    config=config,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e4552d8b8ded6817ca7025bd090f238f9ed63514dd27aca50b11bca35fafaa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
